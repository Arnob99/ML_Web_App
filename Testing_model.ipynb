{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "754e971b-521c-4e25-82e4-45dc95fe171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b7589e9-ef92-4300-aca2-a4d0c31b775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5', compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43f17ea3-70e7-4716-8365-ed17cfd9c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 101, 128)          256000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 101, 202)         185840    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 202)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 202)              808       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 202)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 101)               20503     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 101)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 101)               10302     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 101)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 473,555\n",
      "Trainable params: 473,151\n",
      "Non-trainable params: 404\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "646984c9-6b76-4fa2-8e1a-c22171fffd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0fd8db7-6ae4-4cfd-8532-3de70d962db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, \n",
    "    remove text in square brackets, \n",
    "    remove links, \n",
    "    remove punctuation and \n",
    "    remove words containing numbers.'''\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "440215bc-813f-44c4-b2d4-8dd206c657dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20b72f76-bac2-42ff-9898-ad0d3078778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer('english')\n",
    "\n",
    "def stem_text(text):\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4824acc-c1f0-4594-b884-6f2202539ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stem_text(text)\n",
    "    return pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea72e0a7-b2d3-4106-bcfb-3aa3982dc5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_data(\"Nice video!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86129967-e9bb-4c99-8878-77f757de881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed(corpus): \n",
    "    return tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "train_padded_sentences = pad_sequences(\n",
    "    embed(text), \n",
    "    101, \n",
    "    padding='post'\n",
    ")\n",
    "\n",
    "train_padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e322d03-7a1a-42ff-aa98-0f0166c2ebdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 101)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98513400-cfea-4971-8ee4-572c3c51c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = (model.predict(train_padded_sentences) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d64fa01-361b-4c61-8feb-53406a6790da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a91020-c160-42a4-9b4b-9087a4c64a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
